#!/usr/bin/env python3
"""
å‹•ç”»éŸ³å£°è§£æžã‚¹ã‚¯ãƒªãƒ—ãƒˆ - ç„¡éŸ³åŒºé–“ã‚’æ¤œå‡ºã—ã¦å•é¡Œã‚’ç‰¹å®š

ä½¿ç”¨æ–¹æ³•:
  .venv/bin/python ~/.claude/skills/remotion-qwen-tts/scripts/analyze-video-audio.py out/video.mp4

å‰ææ¡ä»¶:
  - ffmpegãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨
  - numpyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨
"""

import sys
import subprocess
import tempfile
from pathlib import Path

try:
    import numpy as np
    import wave
except ImportError:
    print("numpy ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("pip install numpy ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
    sys.exit(1)


def extract_audio(video_path: Path, output_path: Path) -> bool:
    """å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’ãƒ¢ãƒŽãƒ©ãƒ«WAVã¨ã—ã¦æŠ½å‡º"""
    cmd = [
        "ffmpeg", "-y",
        "-i", str(video_path),
        "-vn",
        "-acodec", "pcm_s16le",
        "-ar", "16000",
        "-ac", "1",  # ãƒ¢ãƒŽãƒ©ãƒ«
        str(output_path)
    ]
    result = subprocess.run(cmd, capture_output=True, text=True)
    return result.returncode == 0


def analyze_audio(wav_path: Path) -> dict:
    """éŸ³å£°ã‚’è§£æžã—ã¦ç„¡éŸ³åŒºé–“ã‚’æ¤œå‡º"""
    with wave.open(str(wav_path), "rb") as wav:
        sample_rate = wav.getframerate()
        n_frames = wav.getnframes()
        audio_data = wav.readframes(n_frames)
        audio = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0

    duration = len(audio) / sample_rate

    # ç„¡éŸ³åŒºé–“ã‚’æ¤œå‡ºï¼ˆRMSãƒ™ãƒ¼ã‚¹ï¼‰
    chunk_size = int(sample_rate * 0.1)  # 100mså˜ä½
    threshold = 0.02
    silence_start = None
    silences = []
    last_sound_time = 0

    for i in range(0, len(audio), chunk_size):
        chunk = audio[i:i + chunk_size]
        if len(chunk) > 0:
            rms = np.sqrt(np.mean(chunk ** 2))
            time_pos = i / sample_rate

            if rms >= threshold:
                last_sound_time = (i + len(chunk)) / sample_rate
                if silence_start is not None:
                    silence_end = time_pos
                    silence_duration = silence_end - silence_start
                    if silence_duration >= 0.5:  # 0.5ç§’ä»¥ä¸Šã®ç„¡éŸ³
                        silences.append((silence_start, silence_end, silence_duration))
                    silence_start = None
            else:
                if silence_start is None:
                    silence_start = time_pos

    # æœ«å°¾ã®ç„¡éŸ³ã‚’ãƒã‚§ãƒƒã‚¯
    tail_silence = duration - last_sound_time
    if tail_silence >= 0.5:
        silences.append((last_sound_time, duration, tail_silence))

    return {
        "duration": duration,
        "last_sound_time": last_sound_time,
        "tail_silence": tail_silence,
        "silences": silences,
    }


def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python analyze-video-audio.py <video_path>")
        print("ä¾‹: python analyze-video-audio.py out/video.mp4")
        sys.exit(1)

    video_path = Path(sys.argv[1])
    if not video_path.exists():
        print(f"ã‚¨ãƒ©ãƒ¼: {video_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)

    print("=" * 60)
    print("å‹•ç”»éŸ³å£°è§£æžã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    print(f"\nå¯¾è±¡: {video_path}")

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«éŸ³å£°ã‚’æŠ½å‡º
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
        tmp_path = Path(tmp.name)

    print("\néŸ³å£°ã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™...")
    if not extract_audio(video_path, tmp_path):
        print("ã‚¨ãƒ©ãƒ¼: éŸ³å£°æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
        print("ffmpegãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        sys.exit(1)

    print("éŸ³å£°ã‚’è§£æžã—ã¦ã„ã¾ã™...")
    result = analyze_audio(tmp_path)

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    tmp_path.unlink()

    # çµæžœè¡¨ç¤º
    print("\n" + "-" * 60)
    print("è§£æžçµæžœ")
    print("-" * 60)
    print(f"  å‹•ç”»ã®é•·ã•: {result['duration']:.2f}ç§’")
    print(f"  æœ€å¾Œã®éŸ³å£°: {result['last_sound_time']:.2f}ç§’")
    print(f"  æœ«å°¾ã®ç„¡éŸ³: {result['tail_silence']:.2f}ç§’")

    # ç„¡éŸ³åŒºé–“
    silences = result["silences"]
    long_silences = [s for s in silences if s[2] >= 3.0]

    print(f"\næ¤œå‡ºã•ã‚ŒãŸç„¡éŸ³åŒºé–“ï¼ˆ0.5ç§’ä»¥ä¸Šï¼‰: {len(silences)}ç®‡æ‰€")

    if silences:
        for start, end, dur in silences:
            if dur >= 3.0:
                print(f"  âš ï¸ {start:.1f}ç§’ ã€œ {end:.1f}ç§’ ({dur:.1f}ç§’) â† é•·ã„ç„¡éŸ³ï¼")
            else:
                print(f"  ðŸ“ {start:.1f}ç§’ ã€œ {end:.1f}ç§’ ({dur:.1f}ç§’)")

    # åˆ¤å®š
    print("\n" + "=" * 60)
    print("è¨ºæ–­çµæžœ")
    print("=" * 60)

    issues = []

    # æœ«å°¾ç„¡éŸ³ãƒã‚§ãƒƒã‚¯
    if result["tail_silence"] >= 10:
        issues.append(f"âŒ æœ«å°¾ã«{result['tail_silence']:.1f}ç§’ã®ç„¡éŸ³ãŒã‚ã‚Šã¾ã™ï¼")
        issues.append("   â†’ Root.tsxã§playbackRateèª¿æ•´ãŒè¡Œã‚ã‚Œã¦ã„ãªã„å¯èƒ½æ€§")
    elif result["tail_silence"] >= 3:
        issues.append(f"âš ï¸ æœ«å°¾ã«{result['tail_silence']:.1f}ç§’ã®ç„¡éŸ³ãŒã‚ã‚Šã¾ã™")
        issues.append("   â†’ pauseAfterã¾ãŸã¯ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ä½™ç™½ãŒå¤§ãã™ãŽã‚‹å¯èƒ½æ€§")

    # é•·ã„ç„¡éŸ³åŒºé–“ãƒã‚§ãƒƒã‚¯
    if len(long_silences) > 0:
        mid_silences = [s for s in long_silences if s[1] < result["duration"] - 1]
        if mid_silences:
            issues.append(f"âš ï¸ å‹•ç”»ä¸­ç›¤ã«3ç§’ä»¥ä¸Šã®ç„¡éŸ³ãŒ{len(mid_silences)}ç®‡æ‰€ã‚ã‚Šã¾ã™")
            issues.append("   â†’ ã‚»ãƒªãƒ•é–“ã®pauseAfterãŒå¤§ãã™ãŽã‚‹å¯èƒ½æ€§")

    if issues:
        for issue in issues:
            print(issue)
        print("\nå¯¾å‡¦æ–¹æ³•:")
        print("  1. Root.tsx/Main.tsxã®playbackRateèª¿æ•´ã‚’ç¢ºèª")
        print("  2. script.tsã®pauseAfterå€¤ã‚’ç¢ºèª")
        print("  3. generate-voices-qwen.pyã®ãƒ•ãƒ¬ãƒ¼ãƒ è¨ˆç®—ã‚’ç¢ºèª")
        return 1
    else:
        print("âœ… å•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼")
        print(f"   æœ«å°¾ç„¡éŸ³: {result['tail_silence']:.2f}ç§’ï¼ˆè¨±å®¹ç¯„å›²ï¼‰")
        return 0


if __name__ == "__main__":
    sys.exit(main())
